FROM nvcr.io/nvidia/cuda:12.8.1-cudnn-devel-ubuntu24.04

# Metadata
LABEL maintainer="HurbaLurba"
LABEL description="ComfyUI optimized for DGX Spark, RTX 6000 Pro Blackwell, and RTX 5090"
LABEL version="0.04"

# Set working directory
WORKDIR /workspace

# Environment variables for optimal GPU performance
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONWARNINGS="ignore" \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    PIP_NO_CACHE_DIR=1 \
    HF_HUB_DISABLE_TELEMETRY=True \
    CUDA_LAUNCH_BLOCKING=1 \
    CUBLAS_WORKSPACE_CONFIG=:16:8 \
    CUDA_DEVICE_MAX_COPY_CONNECTIONS=1 \
    CUDA_DEVICE_MAX_CONNECTIONS=1 \
    CUDA_DISABLE_JIT=0 \
    CUDA_DISABLE_PTX_JIT=1 \
    PYTORCH_JIT_LOG_LEVEL=FATAL \
    TF_CPP_MIN_LOG_LEVEL=3 \
    TF_ENABLE_DEPRECATION_WARNINGS=0 \
    KMP_DUPLICATE_LIB_OK=True \
    NO_ALBUMENTATIONS_UPDATE=1 \
    DEBIAN_FRONTEND=noninteractive

# Install Python 3.12 and system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.12 \
    python3.12-dev \
    python3-pip \
    python3.12-venv \
    git \
    wget \
    curl \
    libgl1 \
    libglib2.0-0 \
    ca-certificates \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Set python3.12 as default python
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.12 1 && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1

# Install PyTorch 2.8 with CUDA 12.8 support (works on both ARM64 and AMD64)
RUN pip install --break-system-packages --no-cache-dir \
    torch==2.8.* \
    torchvision \
    torchaudio \
    --index-url https://download.pytorch.org/whl/cu128

# Install additional Python packages needed for ComfyUI
RUN pip install --break-system-packages --no-cache-dir \
    python-dotenv \
    psutil \
    onnxruntime-gpu

# Clone ComfyUI repository
RUN git clone https://github.com/comfyanonymous/ComfyUI.git /workspace/ComfyUI

# Install ComfyUI requirements (excluding torch packages since we installed them already)
WORKDIR /workspace/ComfyUI
RUN grep -v -E "^(torch|torchvision|torchaudio)$" requirements.txt > /tmp/comfyui_requirements.txt && \
    pip install --break-system-packages --no-cache-dir -r /tmp/comfyui_requirements.txt && \
    rm /tmp/comfyui_requirements.txt

# Install torchao for quantization support
RUN pip install --break-system-packages --no-cache-dir torchao

# Install flash-attention for optimal performance
RUN pip install --break-system-packages --no-cache-dir flash-attn --no-build-isolation

# Install sageattention for attention optimization (set arch list for compilation)
ENV TORCH_CUDA_ARCH_LIST="7.5 8.0 8.6 8.9 9.0 10.0"
RUN pip install --break-system-packages --no-cache-dir sageattention --no-build-isolation || echo "sageattention install failed, continuing..."

# Clone custom nodes
RUN mkdir -p /workspace/ComfyUI/custom_nodes && \
    cd /workspace/ComfyUI/custom_nodes && \
    git clone https://github.com/ltdrdata/ComfyUI-Manager.git && \
    git clone https://github.com/rgthree/rgthree-comfy.git && \
    git clone https://github.com/city96/ComfyUI_ExtraModels.git && \
    git clone https://github.com/city96/ComfyUI-GGUF.git

# Install custom node dependencies if they exist
# Filter out torch/nvidia packages to preserve our PyTorch installation
RUN for node_dir in /workspace/ComfyUI/custom_nodes/*/; do \
        if [ -f "$node_dir/requirements.txt" ]; then \
            echo "Installing requirements for $(basename $node_dir) (preserving PyTorch)"; \
            grep -v -E "^(torch|torchvision|torchaudio|nvidia-)" "$node_dir/requirements.txt" > /tmp/filtered_requirements.txt || true; \
            if [ -s /tmp/filtered_requirements.txt ]; then \
                pip install --break-system-packages --no-cache-dir -r /tmp/filtered_requirements.txt || true; \
            fi; \
            rm -f /tmp/filtered_requirements.txt; \
        fi \
    done

# Create directories for models, input, output, and temp
RUN mkdir -p \
    /workspace/ComfyUI/models \
    /workspace/ComfyUI/input \
    /workspace/ComfyUI/output \
    /workspace/ComfyUI/temp

# Set permissions
RUN chmod -R 777 /workspace/ComfyUI/models \
    /workspace/ComfyUI/input \
    /workspace/ComfyUI/output \
    /workspace/ComfyUI/temp

# Create extra_model_paths.yaml template
RUN echo 'comfyui:' > /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  base_path: /workspace/ComfyUI/models' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  is_default: true' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  checkpoints: checkpoints' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  clip: clip' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  clip_vision: clip_vision' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  configs: configs' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  controlnet: controlnet' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  diffusion_models: |' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '    diffusion_models' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '    unet' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  embeddings: embeddings' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  loras: loras' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  text_encoders: text_encoders' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  upscale_models: upscale_models' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  vae: vae' >> /workspace/ComfyUI/extra_model_paths.yaml.template && \
    echo '  reactor: reactor' >> /workspace/ComfyUI/extra_model_paths.yaml.template

# Expose ComfyUI port
EXPOSE 8188

# Set entrypoint script
COPY entrypoint.sh /workspace/entrypoint.sh
RUN chmod +x /workspace/entrypoint.sh

WORKDIR /workspace/ComfyUI

ENTRYPOINT ["/workspace/entrypoint.sh"]
CMD ["--listen", "0.0.0.0", "--port", "8188"]